=  Oct 26 2009 Conference Call 2:30 pm EDT =

== Agenda/Minutes ==

 # Attendees: 
   * Marcos
   * Maxim 
   * Jason
   * Brian
   * Fahad
   * Jeff
   * Joe
   * Inder
   * Aaron
   * Andy
   * Ezra
 # Developer Updates
   * Marcos
     * Working on [LSScalabilityInvestigation] right now.  See wiki page for updates.
     * Talking with Martin about involving Ahmed in the process - he may start to help.
   * Maxim 
     * Nothing Major
     * Will talk with Aaron about the _service restarting_ work he is doing.
     * Mini-discussion on what Aaron is doing and the other possible approaches (e.g. low level scripts to restart/watch daemons vs something more sophisticated like Nagios).  Will push out to mailing list.
   * Jason
     * BWC - Consuming most time.  Will be uploading some GUIs pretty soon that are being contributed to REDDnet
     * LHC Outreahch
       * USAtlas - Keeping close contact on the open critical bug.  Whole group was a little ticked, but they are happy we are fixing it.  
       * USCMS - Got an invite to the Tier2 Briefing 10/27 - will give a brief talk on the disk, what it is used for, and some recommendations.
   * Brian
     * Nothing
   * Fahad
     * Working with the service in branch
     * Installing SLAC USAtlas servers
   * Jeff
     * At SCinet Staging
     * Deploying perfSONAR servers
     * Note there will be jobs posted for new positions at Internet2
   * Joe
     * Adding 'tasks' to the Issue tracker
   * Inder
     * Still coming up to speed, nothing new to report
   * Aaron
     * Working w/ Andy on the USAtlas bugs
     * SC development (weathermaps)
   * Andy
     * Working w/ Aaron on the USAtlas bugs
     * Setting up a pSB testing and development environment
     * Looking at what it will take to implement the pieces to plot jitter
   * Ezra
     * BWC Prep w/ Jason
     * Giving a talk at SC on Phoebus and Grid FTP
 # Actions from last call:
   * ~~ESnet: add 'current' issues to issue tracker~~
 # pS-Ptk stability update (Andy/Aaron)
   * Andy: Setting up test instances at LBL.  Trying to mimic the setup of USAtlas (in throughput and latency).  Set up on Friday, was hoping to hang it over the weekend, but nothing happened yet.  Have noticed some data points missing
   * Andy: Aaron ha suggested starting 2 master instances to see the effects.  Both are running right now and have not done anything strange.  
   * Aaron: Released 3.1.1a today to Philippe/Shawn at AGLT2.  Hoping to get feedback on:
     * If the fix solves the _full ramdisk_ problem
     * If the fix restarts _down_ services
     * If the fix does not blow away old configurations on disk
   * Will be ready for a release next week if this fix proves ok (need testers).
   * Mini discussion on what the error is vs how to address it.  Aaron explains its related to how knoppix works (it needs a disk, so it mounts the ram disk).  All of our stuff runs _through_ the ramdisk to write the underlying storage (we write to a /scratch file on the real disk).  Joe ponders if this fix was harder or took more time than converting to LiveCD.  Aaron notes that LiveCD will do something similar.
   * Brian mentions that _/var/mail/error_ is filling up with small files - mostly cron errors.  Aaron thinks another cleanup script would work, Brian says we could just stop cron from emailing too.  Joe mentions cfengine scripts as being a solution.
     * _*ACTION*_: Joe will add something to wiki about cfengine.  
   * Jason will relay information to USAtlas on status.  
 # LHC Community Update (Jason)
   * USAtlas - Cheesed off at the error, vented to me last week.  I think they just want to make sure we are are moving on it.  Keeping them updated.  
   * USCMS - Giving a mini talk on pS to this group 10/27.  
 # Coordination of short term GUI development
   * _*ACTION*_: Andy will send a mail to the mailing list outlining what he was tasked with developing.  Aaron/Jason will add to this to see if there is overlap.  
 # What should the ISO do with data longer term? (Requested by Brian)
   * Brian: noticed that the disks are filling up (FAST) with owamp data.  No ability to delete this data (yet).  
   * Jeff: can clear out data on many different levels and solutions can be complex or simple
     * Scripts to backup up
     * Scripts to hot-drop and re-start services
     * Databases vs files
   * _*ACTION*_: Aaron to organize a separate meeting with people interested in this 
 # Terena conference submission?
   * Extended abstract (1-2 pages) due Nov 30th
   * Conference is June 1 in Lithuania
   * Brian wants to submit an ESnet deployment paper
   * Marcos has a paper on IP summarization too.  
 # Future topics:
   * Google MLab
     * It would be great if we could start registering all these nodes in pS.
     * LS archive for finding an NDT server. How do you know what things are available 'publicly' or not.
     * Pushing to make the MLab data available. It would be great if we could provide a pS interface for them.
   * NSF request to fund a workshop for perfSONAR.
     * How would a researcher use pS to fulfill research goals?
     * How do you get tool developers to publish via pS?
     * NSF will be creating a steering committee for this workshop.
     * Hopefully NSF is interested in funding pS.
   * Service Monitoring and Config management
     * gLS 'monitoring'
   * Status collection for low-level device PMs
     * The DCN status page that was put together for the monitoring is a relatively simple collector that grabs various performance counters and other data about elements on the Cienas. Right now, it confines itself to things that look like interfaces. There's a similar project that Jon Dugan has been working on for ESnet called ESxSNMP that grabs performance counters for SNMP hosts. It would be good to have a discussion about how these two monitoring infrastructures might work together. At minimum, it might be feasible to get the TL1 monitoring components to use the same metadata database and counter databases, and, implicitly, perfsonar interface.
     * Another possible area of discussion include how the monitoring above can be extended to support collection and storage of topological information. The topology information could include how interfaces are connected together internally in the switch/router (via cross-connects, adaptation or whatever). It might also be good to think about how to collect information about how switches/routers are wired together.
     * It'd be feasible to grab and store TL1/SNMP alarms as part of the collection framework. Though, that might be more reasonably done via nagios plugins.
     * Currently in the regular testing setup screen, if a user doesn't specify a 'community', the node can not be found. We need to figure out a way to 'find' these nodes. Is there a reasonable way to 'find' them? (Perhaps if there is no 'community' specificied, it should get a 'default' of some kind?)

=== ACTIONS ===

 * _*ACTION*_: Joe will add something to wiki about cfengine. 
 * _*ACTION*_: Andy will send a mail to the mailing list outlining what he was tasked with developing.  Aaron/Jason will add to this to see if there is overlap.
 * _*ACTION*_: Aaron to organize a separate meeting with people interested in this 

== Where ==

ESnet conference bridge:
 * GDS:  00113498255555
 * phone: 1-510-883-7860  then 8255555# at the prompt.
