#labels Phase-Requirements
= Introduction =

The Lookup Service is a critical piece of the perfSONAR infrastructure, and it is important to verify that
the performance scales in all dimensions, including number of clients, number of hLS's, and amount of data being registered in each hLS. 

This page describes a test plan to be performed on the ESnet OpenDevNet. OpenDevNet will allow mutiple VMs to be used to simulate a reasonably large test environment.

= LS Testing Issues =

One must be careful to create a separate gLS/hLS hierarchy for testing, so as to not pollute the global production hLS with bogus data. For more information, see: [http://code.google.com/p/perfsonar-ps/wiki/LocalLSDeployment].
The service emulator [http://anonsvn.internet2.edu/svn/perfSONAR-PS/trunk/client/fakeService/ FakeService] can be used to register data into the hLS. 

For all testing, the following should be monitored and recorded:
 * correctness: are the results correct
 * performance: how long does a client request take
 * load: what is the CPU load on the server
 * DB errors: at what point does xmldb start giving errors (Q: How many errors are acceptable? )

In most cases the goal should be to increase the item being tested until things break.

Another issue is the maximum number of VMs supported by OpenDevNet. This is currently around 15, and will be around 100 in a few months. It should be possible to run multiple instances of client.pl, fakeService.pl, and ls_registration_daemon.pl from the same VM. It is NOT advisable to run multiple hLS or gLS in the same VM. 

== Basic hLS correctness Testing ==

 * register fake services in an hLS, and then write a client to query the gLS for the service, and make sure the results are the same as what was registered. 
 * Q: Are there different types of fake services that should be tested independently? If so, please add details here.

== hLS scalability: number of services registered ==

 * What is the maximum number of services that can be registered by a single instance of `ls_registration_daemon`?
  ** try 10, 25, 50, 100, 250, and 500
 * What is the maximum number of 'fake_services' instances can be run to a single hLS?
  ** try 10, 25, 50, 100

== LS scalability: number of clients ==
 * how many simultaneous clients can contact a single gLS asking for data from the same hLS?
  ** try 10, 25, 50, 100 (try up to 10 per VM)
 * how many simultaneous clients can contact a single gLS asking for data from the different hLSs?
  ** try 10, 25, 50, 100

== gLS scalability: number of hLSs ==
 * what is the maximum number of hLSs that can register to a single gLS?
  ** try 10, 25, 50

== Combined testing ==
 * what is the limit on an hLS as the number of both clients and service registrations increases?
  ** this will test if doing both reading and writing to xmldb is worse that just reading or just writing 
  ** try 10, 25, 50, 100

== Failover Testing ==
 * test the performance for a client to detect a failed server and try the backup server instead.
  ** try 10, 25, 50 simultaneous clients 

=== Test Assumptions  ===
 * each MA registers with 2 hLS's for redundancy
 * the synchronization rate should tested at the following intervals: 
   ** 30,60,120 min updates (Q: is 30 min short enough?)
   ** these should be tested for both service to hLS updates and hLS to gLS, and gLS to gLS synchronization rates

== OpenDevNet VMware Image Notes ==
 * a vmware image with a pre-configured hLS and gLS is available here: XXX
 * hLS/gLS needs an image with 1 GB RAM (verify this)
 * test clients and services only need an image with 512K RAM (verify this too)

= Results =
 
Links to results will be here.