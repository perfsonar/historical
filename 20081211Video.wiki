=  December 11, 2008 Conference Call 4:00 pm EST =

== Agenda/Minutes ==

 # Attendees: Brian, Joe, Aaron, Jason, John Hicks, Maxim, Jeff
 # Issue: Release Management
 # Release Management Czar (Cat herder): Jason Zurawski
   # See [20081211Video#Release_Management_Notes Release Management Notes] for a primer
   # Release TODO:
     * Gather up current documentation of practices, post to wiki
       # CPAN - Aaron
       # RPM - Aaron
       # Deb - Aaron
     * Document New Tasks
       * Release Process (General) - Jason
       * Release Process Specific
         # perfSONAR-PS - Jason (serve as a model for the other projects)
         # BWCTL - Aaron/Jeff
         # OWAMP - Aaron/Jeff
         # NDT - Rich/Aaron
       * Yum Repo - TBD
       * Apt Repo - TBD
       * Ports - TBD
     * Create Roadmap/Milestones - Jeff/Jason
       # perfSONAR-PS - Group Input
       # performance node - Larger Group Input
       # OWAMP - Jeff/Aaron
       # BWCTL - Jeff/Aaron
       # NDT - Rich/Aaron
       # DCN - DCN Folks
       # Phoebus - Martin and Gang
 # Actions/Decisions/Open questions from discussion:
   * *Decision*: Aim for 2 releases a year.
   * *Everyone*: Review branch structure recommendation.
   * *Everyone*: Review release mgmt notes, and make suggestions for changes.
   * *Question*: How will we synchronize release schedules between dependent projects. (i.e. pS-NPToolkit)
   * *Jason*: Add something on integration/interoperability testing to the release. (each service needs to be tested with the other services it is expected to work with - perhaps with older releases of them.)
   * *Brian*: Include Q/A in test framework outline.
 # Next meeting will be Dec 18, 4:00 pm Eastern Time

== Where ==

ESnet conference bridge:
 * GDS:  00113498255555
 * phone: 1-510-883-7860  then 8255555# at the prompt.

== Release Management Notes ==

Content based strongly on the 
[http://www.freebsd.org/doc/en/articles/releng/article.html FreeBSD] process of the same
name.  The following sections highlight the concepts we wish to save and adapt
from this process; note that these are still in strawman form and will be moved
to a permanent home after call.

 # [20081211Video#Milestones_and_Frequency Milestones and Frequency]
   # [20081211Video#2_x_Release_Cycle 2 x Release Cycle]
   # [20081211Video#3_x_Release_Cycle 3 x Release Cycle]
 # [20081211Video#Release_Process Release Process]
   # [20081211Video#Dependencies Dependencies]
   # [20081211Video#Subversion Subversion]
   # [20081211Video#Schedule Schedule]
   # [20081211Video#Documentation Documentation]
     # [20081211Video#Perldoc Perldoc]
     # [20081211Video#Wiki Wiki]
     # [20081211Video#Release_Documentation Release Documentation]
     # [20081211Video#Public_Relations Public Relations]
   # [20081211Video#Testing Testing]
     # [20081211Video#Colored_Box_Approach_To_Testing Colored Box Approach To Testing]
     # [20081211Video#Process Process]
     # [20081211Video#Test_Targets Test Targets]
   # [20081211Video#Code_Review Code Review]
   # [20081211Video#Issue_Tracker Issue Tracker]
 # [20081211Video#Build_Targets Build Targets]

=== Milestones and Frequency ===

We require some _*real*_ project management tools such as charts and the like to
show where we are going with development, and these should be posted either
publicly (here) or privately (spaces wiki?); we will probably want versions of 
both.  These milestones/roadmaps will help us with the release process and also
balance the year's worth of tasks a lot easier.  The last meeting of the year,
or the first meeting of the new year (I would prefer the former) should be used
for roadmap re-evaluation: much like what we did this year.  After a release we
should devote at least part of a meeting to _*lessons learned*_ and 
_*future goals*_ where we can re-evaluate the roadmap.

Currently we are driven to release by conference dates, for the most part we
seem to push hard on development and release for these events:

 * Prior to Joint Techs (Summer or Winter)
 * Prior to Internet2 Member Meetings (Spring or Fall)
 * Misc. Meetings (e.g. LHCOPN)
 
I am proposing we take into consideration these dates and events as they
happen since they are well known and a good indicator of when we will have time
(or not have time), but we should try for regular periodic software release
cycles of the core components on a set schedule.  This does not imply that 
each component will be released on the schedule: we will identify targets
prior to the start of a cycle based on development.  It is probable that only
one or two services may need a release, and this is fine.

The frequency is debatable and does not take into consideration:

 * _bugfix_ releases (this is a separate issue)
 * Intra-project dependencies: Note that perfSONAR-PS now will need to synchronize activities with the performance node project(s), BWCTL, OWAMP, NDT, Phoebus, and possibly DCN.
 
*Group Decision: Initially aim for 2 releases a year.*

Here are some of the options with pro's and con's for two frequencies we should
consider:

==== 2 x Release Cycle ====

6 month release cycles aims for Q1 (Dec/Jan/Feb) and Q3 (Jun/Jul) releases.  This
would coincide with the JTs schedule, but would be tight due to the winter
holidays.  Sliding the window forward a month or two puts it on track for the
Member meeting schedule which may be more palatable (e.g. Mar/Apr and Aug/Sept/Oct).
We *should* avoid releasing in late Oct/Nov at all costs due to SC.  

 * Pro
   * Less man hours on the _paperwork_ aspect of development
   * Twice a year releases shows maturity of the project
   * Ample time for testing of new additions
 * Con
   * Less frequent could imply that the cycle itself would be busy (e.g. several services could make progress in 6 months)
   * May indicate group dormancy (which may or may not be true)
   * If cycle is extended due to elongated testing/bug fix phase could miss the conference deadlines
   * Features take a long time to surface

==== 3 x Release Cycle ====

4 month release cycle tries to coincide with major dates:

 * Dec/Jan/Feb - Winter JTs
 * Apr/May - SMM
 * Aug/Sep/Oct - FMM

The winter holidays complicate this one as well, but by starting a little early
in Dec we can most likely meet the end of January deadline.  I would avoid
shifting this too much into Oct due to the always present Fall member meeting
_big_ demo which Internet2 folks assist with as well as SC commitments.  

 * Pro
   * Mimics current activity cycles closely
   * Shows commitment of the group to constant updates
   * New features show up sooner
 * Con
   * Approaching _too much_ time in release and not enough time in development
   * May push internal resources of all partners
   
=== Release Process ===

The [http://www.freebsd.org/doc/en/articles/releng/article.html FreeBSD] article contains
lots of info, I am going to distill this into the important parts for this meeting
and we can expound upon this at a later day for more detail.  In general most 
Internet2 projects (BWCTL, OWAMP, NDT, performance node, Phoebus, DCN) will be following this
same release blueprint with changes made in the obvious places based on
technologies and manpower when applicable.  The perfSONAR-PS initial release will serve as a test
for the others, so we expect many lessons to be learned the hard way.  There are
a couple things we want to emphasize:

 * [20081211Video#Dependencies Dependencies] - perfSONAR-PS does not sit on an island anymore, we must consider how the release process here will ripple to other projects (and the opposite direction too)
 * [20081211Video#Subversion Subversion] - As pointed out on previous calls, it is less than optimal right now, we will be fixing this
 * [20081211Video#Schedule Schedule] - The schedule should be well spelled out so folks know what to expect and when, the dates will change but the window of time will not
 * [20081211Video#Documentation Documentation] - Major areas must _*~always~*_ be addressed:
   * [20081211Video#Perldoc Perldoc]
   * [20081211Video#Wiki Wiki]
   * [20081211Video#Release_Documentation Release Documentation]
   * [20081211Video#Public_Relations Public Relations]
 * [20081211Video#Testing Testing] - There is some emphasis placed on this, but everyone goes their own way, we must standardize this to do the typical testing (e.g. unit) as well as bigger picture (e.g. protocol and service)
 * [20081211Video#Code_Review Code Review] - This is lacking currently, and that *must* be fixed
 * [20081211Video#Issue_Tracker Issue Tracker] - We are using this pretty well, need some better organization and need to keep up with things that are open and when to close things.

==== Dependencies ====

Using some sort of software, the release manager will need to plot a general and
per-release dependency graph.  This should be shared with other release managers
so the schedule can be adjusted as needed.  Some major dependencies:

 * perfSONAR-PS Components
   * _Should_ be complete prior to performance node release (e.g. the parts that are ready)
   * _Should_ depend on relationship to schedules of other partners (ESnet, Fermi, SLAC, GT, IU, UDel)
   * Dependence on *DCN* (when applicable)
 * performance node (in general - will have specific flavors)
   * _Should not_ release at the same time as other tools; this may be relaxed depending on forecast of things
   * External relationship (weak) on *NPAD*, *Iperf*, *Web100*
 * Phoebus
   * _Should_ depend on certain parts of *perfSONAR-PS* and *DCN*
   * _Should_ depend on needs of *UDel* and *Internet2*
 * OWAMP
   * _Should_ be complete prior to performance node release
   * _May_ run concurrent to *bwctl*, *ndt*
 * BWCTL
   * _Should_ be complete prior to performance node release
   * _May_ run concurrent to *owamp*, *ndt*
   * External relationship to *thurlay*, *iperf*, *nuttcp*
 * NDT
   * _Should_ be complete prior to performance node release
   * _May_ run concurrent to *owamp*, *bwctl*
   * External relationship to *web100* (although this is weak), linux kernel (may trigger security releases)
 * DCN
   * _Should_ take into consideration Phoebus and perfSONAR-PS status (not a hard requirement)
   * External relationship to schedules of other partners (ESnet, MAX)

These will be evaluated on a case by case basis, and overlap will occur both of 
staff and time.  

==== Subversion ====

Our current subversion layout does not follow any rules with regards to tagging, 
branching, or respecting the concept of a release: this is bad.  The FreeBSD
approach is nice, but still a little too much for us:

http://perfsonar-ps.googlecode.com/svn/wiki/20081211Video/branches-head.png

Borrowing some concepts from both 
[http://www.freebsd.org/doc/en/articles/releng/article.html FreeBSD] and 
[http://svnbook.red-bean.com/en/1.5/svn-book.html#svn.branchmerge SVN], here is
the proposed layout of our tree:

http://perfsonar-ps.googlecode.com/svn/wiki/20081211Video/svn.png

This implies a couple of immediate changes (pre-release process)

 * Clean up old branches
 * Clean up old tags
 * Clean up trunk of certain aspects
   * the module substructure - more on this later
   * doc skeleton structure
   * remove or move misc. debris

The actual release process then requires these actions

 * The release manager should be the one to manage the SVN tags, branches.  
   * Documentation of this process is a must
   * Adherence to the process is a must
 * Prior to release, the Release manager prepares the RELEASE_X_Y Branch.
   * If not done already, services involved in release must become stable ASAP in this branch, fixes done here can be merged back to trunk.
   * The 15 Day window to slush involves still working from trunk (to prevent this from becoming un-stable), bugfixes and new functionality that makes the cut before the 15 minute window can be merged in after testing.
 * Tags are prepared from the RELEASE branch for milestones (e.g. RCs, Betas, Releases)
 * Over time, bugfixes from trunk can be applied to branches
   * New tags may be created

The release _tooling_, e.g. the way it is packaged as an RPM or CPAN package is
is currently kept in the development tree.  An idea was floated to change this:

 * Maintain a separate repo just for release information on a service by service basis
 * Remove existing _module_ information from development subversion
 * Release mangement repo will contain release information for each service in the various formats
 
This idea should be discussed.
 
==== Schedule ====
 
The following diagram lays outs the release schedule:

http://perfsonar-ps.googlecode.com/svn/wiki/20081211Video/schedule.png

Overview: 45 Day process, can be lengthened in special circumstances.

 * Days < 0
   * Release manager starts to identify targets over mailing list
   * conf call before release time to finalize details
   * Milestones/Roadmap updated as needed
 * Days 1 - 15: 
   * Announce Release Cycle Start
   * Announce Targets
   * Draw up Release Plan with any specifics over the general plan
   * Release manager prepares RELEASE branch
   * Developers: 15 days to get RELEASE stable and merge in bugfixes/improvements
   * Developers: start to finalize doc
   * Release manager rounds up community members for later testing (announce to relevant lists - maintain static list in a private location)
   * End of phase is make or break for release inclusion for specific products
   * Code Review Begins
 * Days 16 - 30:
   * Code Slush - all non critical source code moves to RELEASE are halted
   * Documentation may be updated
   * Test cases may be updated
   * Internal testing and building begins
   * Code Review continues as necessary.
 * Days 31 - 45:
   * RC process begins.
     * New Tags from RELEASE when applicable 
   * Target should be for ~3 RCs (every 4 days until release) but will also depend on what issues are found and how often a build is necessary.  
   * Testing with _interested_ community members (aim for RCs 1 and 2, by 3 its too late).  
   * Make call to extend to additional RCs if necessary
 * Day 45
   * Release announcement
   * Upload to various sources in various forms
   * Adjust Issues/Wiki/Web pages as needed
 * Day 46+
   * Adjust milestones/roadmap
   * Lessons learned
   * Changes in Direction
 
==== Documentation ====
 
Keeping up with documentation is a must, and all _levels_ of documentation
should be addressed by the necessary parties:

 # [20081211Video#Perldoc Perldoc]
 # [20081211Video#Wiki Wiki]
 # [20081211Video#Release_Documentation Release Documentation]
 # [20081211Video#Public_Relations Public Relations]

===== Perldoc =====

 * Author: Developers
 * Editor: Other Developers  

If you aren't documenting as you develop, this will be a painful thing.  All
perldoc must be relevant to a current release, and the code review should
ensure this.  This includes documenting functional inputs and ouptputs as well
as the module use, includes, and licence info.   
 
Modules/Services not in accordance to this rule will be omitted from release.

===== Wiki ===== 

 * Author: Developers
 * Editor: Other Developers  

Take what you wrote in perldoc, and expound only a little bit more.  Include
more examples when relevant.  Keeping this up to date is critical (e.g. it will
be a release task).  

===== Release Documentation ===== 

 * Author: Developers
 * Editor: Release Manager + Tech Writer

Build this from the previous two, really only interested in a couple of formal
things:

 # INSTALL - instructions for installation
 # README - any specific notes
 # Changes - since the last time
 # Other specific relevant documentation like a users guide (varies by service)

Release manager and Tech writer should comb this over before the announcement
for completeness.
 
===== Public Relations ===== 
 
 * Author: Release Manager, Manager
 * Editor: Tech Writer, Marketing
 
Built from the previous sections, should be the bright and shiny portion that
talks at a high level.  Release and Project manager should coordinate this with
the marketing folks to get what we want.  Target is for release date. 
 
==== Testing ====

Not a lot of emphasis thus far has gone into our testing.  We do not have the
manpower or time to maintain a full time test team, so using some typical
approaches in a succinct manner should get us further along to a testing goal.
[http://en.wikipedia.org/wiki/Software_testing#Testing_methods This] page is the
starting point for this section:

===== Colored Box Approach To Testing =====

I am avoiding using a specific major color since we will need a hybrid approach
for the time and resources allowed.  Here are the classic choices:

 * Black Box - Test not knowing or caring how it works (just that it does).  Use of existing test harness is probable
 * White Box - Having knowledge of what is inside, test to see it works as it should.  Use of external tools like profilers and the like 
 * Gray Box - Hybrid of the two, you know how it works and use this to design external tests

I would advocate that we create a pretty large set of black box tests for the service level (e.g. library of messages for each service) that test the common cases, the failure cases, and the corner cases (will need white box knowledge for these).  For the lower levels (functional tests) that can be expressed in the perl test language we can also take a more black than white line to testing.

===== Process =====

There are 3 areas we need to address

 # Unit tests - written in the perl testing method for perfSONAR-PS, JUnit for the Java tools, and more manual methods for other software.  Should hit all functions.
 # Integration testing - test that the interfaces to modules/classes are clean
 # System Testing - Protocol level testing for the various components
 
Individual documents should go into more details here.

===== Test Targets =====

The test farm was an idea initially discussed more for the non perl services
(e.g. BWCTL, OWAMP are a little closer to the hardware) but the idea will still
benefit perfSONAR-PS:

 * Dedicated development machines either in Ann Arbor or other partner's facility
 * Major architectures:
   * i386
   * x86_64
   * SPARC
   * ?
 * Major flavors
   * Debian/Ubuntu
   * RHEL/Fedora/Scientific
   * Solaris
   * Free/Open/Net BSD (Free will suffice)
   * ?
 * Recent versions of each of the major flavors.

Having individual machines for this is not cost effective, so virtual machines
seems to be the best way.  Internet2 currently has a dedicated machine for this
(not sure of the exact details - coming soon, but beefy and probably Intel based)
where it is possible to call up a VM and have it go 'live' in moments.  We
doubt we could use the 'production' machine for dev purposes but a similar
setup would be good.

The goal would be to keep snapshots of clean OSs for instant startup where we
can test various things.  Ideas on this are welcome.

==== Code Review ====

Code review also has two parts:

 * Pre-review tasks the developer will do including running tidy and critic to get the major things out of the way.
   * The idea was floated (a long time ago) to automate this via SVN hooks, we should re-evaluate this 
 * Actual code review done by the entire project.

Code review will be a part of *_every_* release cycle.  It will go down as such:

 * Release manager will identify the files to be reviewed
 * Release manager will divy up by either file or function (the process of dividing is really a review in and of itself) and try to give related chunks to the reviewers (e.g. *_all of pS-PS_*).  There will be overlap.
 * Purpose of the review should be:
   * Critique the organization/layout - this is our only way to make things better
   * Question the use of external libs
   * Question Algorithmic design/use - this is also very important for services like the LS/TS/IS and the general design of MAs and MPs.  
   * Critique of documentation (also a must).  
 * Reviewers will have a finite amount of time (TBD) to complete a review.
 * Reviews should follow some format (TBD also) and shared on the mailing list for additional comments). 
 * Developers will have a shorter finite amount of time to fix changes.
 * Release manager will do final review of changes.

==== Issue Tracker ====

Use of this so far has been good.  Some improvements:

 * Keep _labels_ up to date - especially milestones (need labels), products, versions, etc.
 * Re-classify existing bugs when applicable to specific release targets
 * Use the _depends on_ feature more to link issues
 * Close out bugs when we can, don't leave open for an indefinite amount of time
 * Watch the _assigned to_ person when bugs are opened - this can always be changed but make a good guess who this should be, when in doubt pick the release manager
 
=== Build Targets ===

The following will represent the _types_ of release we *must* have:

 * RPM packages
   * Tested on RHEL 4/5, Fedora Current 8/9/10, Scientific, CentOS
 * Deb Packages
   * Debian Stable/Testing, Ubuntu -2, -1 and 0
 * FreeBSD Ports
 * Source TAR/BZ/ZIP
   * Mimic CPAN structure (e.g. MakeMaker)
 
The following are still good, but are slipping to the *would like* category:

 * CPAN - Does making it available here buy us anything?
 
Additionally we will want to make an apt/yum repo available.  Developing.

== Last Updated ==

$Id$
